---------------------------------------------------------------------------------------------------

Additional softwares after a fresh Linux installation:

    super-boot-manager (http://www.sourceslist.eu/projects/super-boot-manager)
        sudo add-apt-repository ppa:ingalex/super-boot-manager
        sudo apt-get update
        sudo apt-get install super-boot-manager

---------------------------------------------------------------------------------------------------

running a simple HTTP server:
(http://www.linuxjournal.com/content/tech-tip-really-simple-http-server-python)
python -m SimpleHTTPServer

connect using: http://127.0.0.1:8000/tmp

---------------------------------------------------------------------------------------------------

Installing perl modules:
------------------------
Many perl scripts use modules (e.g. `use Archive::Ar;`). To install missing modules, use cpanm.
    - sudo apt-get install cpanminus
    - cpanm Archive::Ar
cpanm would normally automatically install all the dependencies also. Without 'sudo' installation
will happen to a directory in your home directory (e.g. /home/gautam/perl5).
Sometimes, installation fails (usually because some dependency could not be automatically
installed). In this case, find the dependency whose installation failed (using the log file whose
location would be helpfully indicated by cpanm) and install the dependency manually. For example, if
'Test::Exception' is a dependency whose automatic installation failed, then just run
    - cpanm Test::Exception
Then retry the original installation.

Finally, to run the perl script that was using the newly installed modules, you need to specify the
location of the newly installed modules using,
    - export PERL5LIB=/home/gautam/perl5/lib/perl5

---------------------------------------------------------------------------------------------------

To cut the last field (using space as delimiter):
    awk -F" " '{print $NF}'
        OR
    rev | cut -d" " -f1 | rev

To print the 3rd field using awk:
    echo "a b c d e" | awk '{print $3}'

To remove leading whitespace:
    echo "   	   blah" | awk '{$1=$1};1'

To squeeze/compress multiple spaces into one:
    echo "hey     there" | tr --squeeze-repeats " "

---------------------------------------------------------------------------------------------------

Alternative way to do:
    for file in `ls`; do echo $file; done
is:
    ls | while read file; do echo $file; done

---------------------------------------------------------------------------------------------------

copy contents of a file into the clipboard:
-------------------------------------------
    cat file | xclip -in -selection clipboard     // puts into the Ctrl+Shift+V clipboard
        OR
    cat file | xclip                              // puts into the Shift+Insert (middle mouse-button clipboard)

---------------------------------------------------------------------------------------------------

list files with blank lines at the end:
---------------------------------------
    for F in `ls {src,test}/**/*.d`; do S=$(tail -1 ${F}); [ -z ${S} ] && echo ${F}; done

---------------------------------------------------------------------------------------------------

To get the sizes of files (without an overwhelming amount of output), use:
    du -ckhs *
    (I don't yet know the reason for the 'k', as 'du -chs *' seems to give the same output)

---------------------------------------------------------------------------------------------------

To get the amount of disk space used & free:
    df -hT | egrep -i "file|^/"

---------------------------------------------------------------------------------------------------

To grep for tabs in a file
    grep $'\t' <filename>

---------------------------------------------------------------------------------------------------

The output of 'echo' can be controlled by using certain "Terminfo Capabilities", e.g:
    prompt$> tput smso; echo "hello world"; tput rmso
(more here: http://tldp.org/LDP/lpg/node126.html)

---------------------------------------------------------------------------------------------------

To run a command at startup, there are 2 options:
    1. sudo crontab -e
       add the following in the end:
           @reboot <<command_to_run>>
      OR
    2. create a script file with your command
       make the script executable
       sudo /etc/rc.local
       path to your script at the end just above exit 0
So what's the difference?
    For the most part they're equivalent. The part where they differ is precisely when they run the
    command. /etc/rc.local is the last item to run, after all the other services have started.
    I don't yet know when @reboot runs.

---------------------------------------------------------------------------------------------------

[15:47:45] Nemanja Boric: btw, good thing for debugging: setarch i686 -R gdb ./program
[15:47:51] Nemanja Boric: removes address randomization

---------------------------------------------------------------------------------------------------

To cherry-pick all commits on a branch on top of another branch:
----------------------------------------------------------------

    Goal: cherry-pick source_branch commits over target_branch
          (i.e. commits Cy & Cz over commit C6)

               C6 o           => target_branch
                  |
               C5 o  o Cz     => source_branch
                  |  |
               C4 o  o Cy
                  |  |
               C3 o  o Cx     => some_intermediate_branch
                  |  |
               C2 o---
                  |
               C1 o

    1. git checkout target_branch
    2. git rebase --onto HEAD Cx source_branch
           (commit Cx will not be picked - only commits Cy & Cz will be picked and applied above
           commit C6)
           (if instead of source_branch, only the commit hash was used, i.e. Cz, then source_branch
           will not be moved from its original location)

---------------------------------------------------------------------------------------------------

Setting date from the command-line:
-----------------------------------
    sudo date MMDDHHMMYYYY.SS
              |     |
            month  minutes

---------------------------------------------------------------------------------------------------

Expandable GitHub comments:

<details>
  <summary>Click to expand</summary>
                                             <--- this blank line is necessary for proper formatting
  whatever
</details>

---------------------------------------------------------------------------------------------------

Installing a package on Arch Linux from AUR:
--------------------------------------------
    - download the package archive from AUR ("Download snapshot" link in the
      "Package Actions" box on the right) to `~/aur`
    - extract the archive, then delete it
    - cd to the extracted directory
    - makepkg -Acs
    - sudo pacman -U <tar.xz>

---------------------------------------------------------------------------------------------------

If you need to use different GitHub accounts on the same computer:
------------------------------------------------------------------
    The idea is to present different ssh keys to GitHub for the different
    accounts.

    - use different git remote URLs of the form:
          git@github-BLAH:...
          (where BLAH is a decent descriptive string)
    - add a section in `~/.ssh/config` of the form:
      ```
      Host github-BLAH
          Hostname github.com
          User git
          IdentityFile ~/.ssh/id_ed25519_blah   <-- path to proper ssh key
          IdentitiesOnly yes
      ```

    This may be helpful if you run into problems:
    http://code.tutsplus.com/tutorials/how-to-work-with-github-and-multiple-accounts--net-22574

---------------------------------------------------------------------------------------------------

To run an SFTP server in a docker container:
--------------------------------------------
    USERNAME="user"
    PASSWORD="password"
    HOST_DIR_TO_SHARE="/path/to/shared/directory"
    DIR_IN_CONTAINER="/home/${USERNAME}/share"

    docker run -d -v "${HOST_DIR_TO_SHARE}:${DIR_IN_CONTAINER}" -p "2222:22" atmoz/sftp:alpine ${USERNAME}:${PASSWORD}:1001

    testing:
        confirm the container is running and get its name using `docker ps`
        CONTAINER_NAME="..."
        IP_ADDR=$(dcipaddr ${CONTAINER_NAME})
        sftp ${USERNAME}@${IP_ADDR}
        enter ${PASSWORD} when prompted
        ls, get etc.

    if you want other options e.g. logging in with SSH keys only etc., check out https://hub.docker.com/r/atmoz/sftp

---------------------------------------------------------------------------------------------------

Check in Makefile if docker container is already running:
---------------------------------------------------------
check:
	@set -e; \
	CONTAINER_NAME=blah; \
	if [ `docker ps --quiet --filter status=running --filter name=$${CONTAINER_NAME}` ]; then \
		echo "Container '$${CONTAINER_NAME}' is running." && false; \
	fi
---------------------------------------------------------------------------------------------------

To create a password protected archive:
---------------------------------------
1. Generate a password (e.g. using `gopass generate -p tmp`)
1. Create a file (say `/tmp/password.txt`) containing the following line
   ```
   PASSWORD=<the-generated-password>
   ```
1. export $(xargs < /tmp/password.txt)
1. 7z a archive_name.7z * -p${PASSWORD}
   (here `*` makes all files in the directory to be added to the archive.
   Individual file names can also be specified if necessary.)

---------------------------------------------------------------------------------------------------

Installing the Tela grub theme:
-------------------------------

This is needed only if you use grub as the bootloader. You'd use grub as the
bootloader only if EFI isn't supported (because otherwise you'd simply use
rEFInd).

1. Go to https://www.gnome-look.org/p/1307852/
1. Go to the `Files` tab and download `Tela-1080p.tar.xz`
1. extract Tela-1080p.tar.xz
1. cd Tela-1080p
1. sudo ./install.sh
1. reboot

---------------------------------------------------------------------------------------------------

Workaround for journalctl not accepting ISO8601 times:
------------------------------------------------------

    ➜ SINCE=$(date -d '2021-01-01T13:00:00' +%s)
    ➜ sudo journalctl --since=@${SINCE} --unit=whatever.service

---------------------------------------------------------------------------------------------------

## To give SSH access from outside the home network

1. Set up dyn-dns so the remote end doesn't need to always know the present
   public IP address
1. Enable port-forwarding on the router (SSH uses port 22)
1. Set up a guest account
1. sudo systemctl start sshd
1. Connect from outside using `ssh guest@<dyn-dns-domain>`

---------------------------------------------------------------------------------------------------

## Enabling port-forwarding on the router

1. Login to router
1. Left column -> Internet -> Freigaben
1. Click the button `Gerät für Freigaben hinzufügen`
1. If the device exists under `Gerät`, choose it and confirm the IP address; if
   it doesn't choose `IP Adresse manuell eingeben` and manually enter the IP
   address
1. Click the button `Neue Freigabe` on the bottom right
1. Under Anwendung, choose `Andere Anwendung`
1. Under Bezeichnung, enter `SSH`
1. Under Protokoll, choose `TCP`
1. Under Port an Gerät, enter von 22 bis 22
1. Under Port extern gewünscht, also enter 22
1. Confirm that `Freigabe aktivieren` is checked, and select
   `Internetzugriff über IPv4 und IPv6`
1. Click OK
1. Again click OK

---------------------------------------------------------------------------------------------------

## Accessing a hard-disk connected to the router

1. Login to router
1. Left column -> Heimnetz -> Speicher (NAS)
1. Under `Speicher (NAS) aktiv`, click on `USB-Speicher`
1. Click on the hard-disk folder (which should be the last entry on the page)

## To stream a video

1. Find the video you want to stream
1. Right-click -> Freigeben
1. Copy the download link
1. Open VLC media player
1. Media -> Open Network Stream
1. Paste the link
1. It may show some errors about invalid certificate, which you can safely
ignore
1. Enjoy

---------------------------------------------------------------------------------------------------

bash script confirmation:
-------------------------

empty means "No":
    read -p "Continue? (y/N): " YES_OR_NO
    [ -z "${YES_OR_NO}" ] || [[ "${YES_OR_NO}" != [yY] ]] && echo "Canceled." && exit 1

empty means "Yes":
    read -p "Continue? (Y/n): " YES_OR_NO
    if [ ! -z "${YES_OR_NO}" ]; then
        [[ "${YES_OR_NO}" != [yY] ]] && echo "Canceled." && exit 1
    fi

In zsh scripts, change `read -p "Continue? ...` to `read "?Continue? ...`
IOW, remove the `-p` option, and prefix a `?` to the prompt.

---------------------------------------------------------------------------------------------------

truncating long strings in a Go program:
----------------------------------------
trunc := func(s string, max int) string {
    if len(s) <= max {
        return s
    }

    delta := len(s) - max
    suffix := "s"
    if delta == 1 {
        suffix = ""
    }

    // Note: The "plus N more characters" suffix that is added when truncating
    // the string causes the final string to not really respect the specified
    // maximum limit. This should be properly handled if this ever becomes a
    // first-class utility function.
    return fmt.Sprintf("%s <plus %d more character%s>", s[:max], delta, suffix)
}

str := "... a really long string ..."
truncateTo := 100
fmt.Println(trunc(str, truncateTo))

---------------------------------------------------------------------------------------------------

printing an io.Reader in a Go program:
--------------------------------------
buf := new(strings.Builder)
io.Copy(buf, reqBody) // reqBody is an io.Reader
fmt.Println(buf.String())

---------------------------------------------------------------------------------------------------

when dealing with Go channels:
------------------------------
. when declaring/passing channels, always specify whether it'll be used for
  reading/writing
. the function writing into a channel should be responsible for closing it
  (because only the writer knows when it is done writing)
. when reading from a channel, prefer to use `for r := range channelNameCh { ... }`

    * send to nil channel         --> blocks forever
    * receive from nil channel    --> blocks forever
    * send to closed channel      --> panic
    * receive from closed channel --> immediately returns zero value

---------------------------------------------------------------------------------------------------

when dealing with Goroutines:
-----------------------------
. telling a goroutine to finish up:
      if the goroutine is already reading from a channel:
          simply close the channel
      else:
          give the goroutine a done channel, and close that
. when a goroutine finishes, it needs to signal its completion
      if the goroutine is already writing into a channel:
          simply close the channel
      else:
          defer wg.Done() (or defer doneFn())

---------------------------------------------------------------------------------------------------

Converting wav files to mp3 (ripping a cd):
--------------------------------------------
    1. Plug-in the CD drive containing the CD
    2. Open a terminal at that location
           a simple way would be to open the directory in nautilus, right-click -> Open in Terminal
           (the last time the path was `/run/user/1000/gvfs/cdda:host=sr0`)
    3. Create a temporary directory to save the output files - `D=$(mktemp -d)`
    4. for F in *.wav; do ffmpeg -i ${F} -vn -ar 44100 -ac 2 -b:a 192k ${D}/${F%.wav}.mp3; done
    5. cd ${D}
    6. [Optional] Convert spaces in filenames to underscores
       for F in *; do NEW_NAME=$(echo ${F} | sed 's/\s/_/g'); mv ${F} ${NEW_NAME}; done
    7. Play the files saved in $D to check if they're OK

---------------------------------------------------------------------------------------------------

Using grep in a shell script with 'set -euo pipefail':
------------------------------------------------------
In a shell script that uses 'set -euo pipefail', some extra work needs to be
done when using grep (in cases where the pattern being searched for not existing
is not an error condition). Or else, the script would immediately exit if the
pattern being searched for doesn't exist in the file.

In this case, a '||' is used after the grep command so that the line as a whole
always succeeds. The status of the grep command is later checked to determine
the next course of action.

According to
https://pubs.opengroup.org/onlinepubs/9699919799/utilities/grep.html#tag_20_55_14,
grep's status codes have the following meaning:
    0  => pattern was found
    1  => pattern was not found
    >1 => some error occurred

Here's a sample code snippet:

    GREP_STATUS=-1
    grep --silent pattern file || GREP_STATUS=$?
    if [ ${GREP_STATUS} -eq 1 ]; then
        # Do whatever needs to be done if the pattern was not found
    elif [ ${GREP_STATUS} -gt 1 ]; then
        exit ${GREP_STATUS}
    fi
    # Do whatever needs to be done if the pattern was found

---------------------------------------------------------------------------------------------------

RabbitMQ general info:
    https://stackoverflow.com/a/48770082/793930

---------------------------------------------------------------------------------------------------

Enabling redis notifications for expiring keys:
-----------------------------------------------
- connect to the redis server of interest using `redis-cli`
  (ProTip: on Windows, use "Another Redis Desktop Manager")
- change to the database of interest using `SELECT <db-number>`
- check the value of the current setting using `CONFIG GET notify-keyspace-events` (will probably be empty)
- enable keyspace notifications using `CONFIG SET notify-keyspace-events Ex`
- check the value once again using `CONFIG GET notify-keyspace-events` (should now be set correctly)
- To make the change persist across restarts of the redis server, open
  `/etc/redis/redis.conf`, look for `notify-keyspace-events` and set its value
  to `Ex`.

To confirm whether expiration events are being sent as expected:
----------------------------------------------------------------
in the redis-cli, simply subscribe to key expiration events using `PSUBSCRIBE __keyevent@<db-number>__:expired`
(so for db0, this'll be `PSUBSCRIBE __keyevent@0__:expired`)
if there's no activity, then maybe nothing is expiring
in this case, set a temporary key along with a short expiry
    SET tempkey tempvalue
    EXPIRE tempkey 30
then subscribe and wait for the temporary key to expire

---------------------------------------------------------------------------------------------------

On Microsoft SQL Server database:
---------------------------------

To find the current max ID:
    SELECT MAX([Id]) FROM <TABLE_NAME>

To check what the next ID will be:
    SELECT IDENT_CURRENT('<TABLE_NAME>') + IDENT_INCR('<TABLE_NAME>') AS NextIdentityValue;
    (if you get NULL, check if you've inserted the correct table name in both places)

To set the next ID:
    DBCC CHECKIDENT ('<TABLE_NAME>', RESEED, <CURRENT_MAX_ID>);
                                                     |
                                                     └-> a row with this ID should already exist

To get an idea of what a particular process is waiting for:
    SELECT * FROM sys.dm_exec_session_wait_stats WHERE session_id = 123 ORDER BY wait_time_ms DESC
                                                                    |
                                                                    └-> you'd usually get this ID from the
                                                                        "Blocked By" column in
                                                                        Activity Monitor -> Processes

---------------------------------------------------------------------------------------------------

[C#] To test a NuGet package locally before releasing it:
---------------------------------------------------------
1. Confirm that the local NuGet package builds successfully.
1. Confirm that the application that uses the NuGet package builds successfully.
1. Commit all the changes in the NuGet package.
1. Commit all the changes in the application.
1. Identify all the projects in the application solution that use the NuGet
   package.
1. Open the .csproj file of all these projects and delete the `PackageReference`
   lines where the NuGet package gets included. Confirm that the application now
   has build errors.
1. Right click the top-level solution (not one of the projects), click on "Add",
   and then "Existing project".
1. Find the .csproj file of the NuGet package and choose it to add the NuGet
   package as a project to the solution.
1. Do the following for each project in the application that uses the NuGet
   package (called `PROJ` in the box below).
   ```
   * In a terminal, go to the directory of PROJ (this is usually one level below
     the root of the repository).
   * Use `ls` to find the relative path from this directory to the .csproj file
     of the NuGet package. Copy this relative path.
   * Open the .csproj file of PROJ and add a new `ProjectReference` line (not a
     new `PackageReference` line). The `Include` value in this line should be
     set to the relative path copied earlier.
   ```
1. Confirm that the application builds successfully once again.
1. Make a temporary commit so that it can be easily reverted after testing.

---------------------------------------------------------------------------------------------------

Useful helm commands:
---------------------

To view the current release:
----------------------------
➜ NS=my-awesome-namespace
➜ DEPLOYMENT_NAME=my-awesome-deployment
➜ helm list --namespace=${NS} --filter=${DEPLOYMENT_NAME}
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART
blah-blah       blah-blah       8               2024-11-28 09:42:20.917525917 +0000 UTC deployed        some-chart-name
                                |
                                └-> this is the currently running version

To see all available releases:
------------------------------
➜ NS=my-awesome-namespace
➜ DEPLOYMENT_NAME=my-awesome-deployment
➜ helm history --namespace=${NS} ${DEPLOYMENT_NAME}
REVISION        UPDATED                         STATUS          CHART
4               Fri Aug 25 14:51:26 2023        superseded      some-chart-name
5               Fri Oct  6 22:06:16 2023        superseded      some-chart-name
6               Wed Oct 25 08:11:39 2023        superseded      some-chart-name
7               Mon Oct 30 11:04:02 2023        superseded      some-chart-name
8               Thu Nov 28 09:42:20 2024        deployed        some-chart-name
|
└-> this column lists all the available versions

To rollback to a particular release:
------------------------------------
➜ NS=my-awesome-namespace
➜ DEPLOYMENT_NAME=my-awesome-deployment
➜ VERSION_TO_ROLLBACK_TO=7
➜ helm rollback --namespace=${NS} ${DEPLOYMENT_NAME} ${VERSION_TO_ROLLBACK_TO}
                                                     |
                                                     └-> if the version to rollback to is omitted,
                                                         the previous version is chosen by default

---------------------------------------------------------------------------------------------------

